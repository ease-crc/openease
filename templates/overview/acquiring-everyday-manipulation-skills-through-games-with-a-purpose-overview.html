{% extends "overview/overview_template.html" %}

{% block overview_title %}
    Acquiring Everyday Manipulation Skils through Games with a Purpose
{% endblock %}

{% block overview_main %}
    <div class="row">
        <div class="col-12 col-md-5 px-0">
            <p>
                Autonomous robots for performing manipulation tasks such as flipping a pancake or fishing a sausage out of the cooking pot require a lot of knowledge that cannot be easily expressed and formalized in knowledge bases and knowledge representation languages. We ask video game players to perform such actions in simulation-based virtual reality environments and acquire such knowledge from the logfiles of the game episodes.The Games with a Purpose dataset contains episodes of humans demonstrating pancake-making in a virtual reality setting. This data is then used for action recognition and parameterization.
            </p>
            <a type="button" class="btn link-button"
            href="https://neemgit.informatik.uni-bremen.de/raw/acquiring-everyday-manipulation-skills-through-games"
            target="_blank" rel="noopener noreferrer">
                Knowledge Base
            </a>
            <a type="button" class="btn link-button"
            href="http://www.open-ease.org/acquiring-everyday-manipulation-skills-through-games-with-a-purpose-work/"
            target="_blank" rel="noopener noreferrer">
                Publications
            </a>
        </div>
        <div class="col-12 col-md-7 px-0 mt-4 mt-md-0 mb-3">
            <div class="pl-md-4">
                <div class="video-container">
                    <iframe class="responsive-iframe"
                    src="https://www.youtube.com/embed/-CgZbNe3cx0?feature=oembed"
                    frameborder="0" allowfullscreen></iframe>
                </div>
            </div>
        </div>
    </div>
{% endblock %}


{% block details %}
    <div class="row ">
        <div class="col-12 px-0">
            <p>
                In order for future robots to successfully accomplish more and more complex manipulation tasks, they are required to be action-aware and possess naive physics reasoning capabilities. They need to possess a model regarding how the effects of their actions depend on the way they are executed. For example, a robot making pancakes should have an understanding that pouring the pancake-mix on the oven depends on the position and the way the container is held, or that sliding a spatula under a pancake may or may not damage it depending on the angle and the dynamics of the push.
            </p>
        </div>
        <div class="col-12 col-md-6 offset-md-3 pt-4 px-0">
            <div class="pt-3 pt-md-0 pb-2">
                <center>
                    <a href="{{ url_for('static', filename='img/overview/knowledge-games-with-a-purpose/setup_cutout.jpg')}}">
                        <img class="col-12 mb-3"
                        src="{{ url_for('static', filename='img/overview/knowledge-games-with-a-purpose/setup_cutout.jpg')}}"
                        alt="">
                    </a>
                    <p>
                        Setup of the virtual environment game
                    </p>
                </center>
            </div>
        </div>
    </div>

    <div class="row flex-column">
        <p>
            The setup for data collection is depicted in the figure above. The system is provided with a sensor infrastructure that allows interaction with the virtual world by tracking the playersâ€™ hand motion and mapping them onto the robotic hand in the game. We tested out two different setups for the tracking. One with the help of a magnetic sensor based controller, which returns the position and orientation of the hand, together with a dataglove for finger joints positioning. In the second case we used two 3D camera sensors mounted on a frame which yields the pose and the skeleton of the tracked hand.
        </p>

        <h3>
            Description of the Data
        </h3>
        <p>
            This dataset contains the following data:
        </p>
        <ul class="details-list">
            <li>
                Semantic memory (represented using Web Ontology Language, OWL) of all performed actions, and their parametrizations and outcomes
            </li>
            <li>
                Physical pose and transformation data of all the objects in the virtual world
            </li>
        </ul>
    </div>
{% endblock %}



{% block acknowledgements_class %}
{% endblock %}

{% block acknowledgements %}
    <p>
        Partly supported by the EU FP7 RoboHow project
    </p>
    <div class="row pt-md-3 pb-5 justify-content-center">
        <a class="pb-3 pb-md-0 mx-md-3" href="http://www.robohow.eu/"
        target="_blank" rel="noopener noreferrer">
            <img class="col-12"
            src="{{ url_for('static', filename='img/overview/acknowledgements/robohow.png')}}"
            alt="robohow logo">
        </a>
    </div>
{% endblock %}
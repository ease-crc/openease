{% extends "overview/overview_template.html" %}

{% block overview_title %}
    Perception for Everyday Manipulation
{% endblock %}

{% block overview_main %}
<div class="row">
    <div class="col-12 col-md-5 px-0">
        <p>
            A great challenge in everyday manipulation are the perceptual capabilities required for their successful accomplishment.
        </p>
        <p>
            In our perception framework, RoboSherlock, we investigate techniques for combining knowledge processing and reasoning with robot perception mechanisms, while maintaining a close integration with planning libraries.
        </p>
        <a type="button" class="btn link-button mb-2"
        href="http://www.open-ease.org/knowledge-based-reasoning-in-robosherlock/"
        target="_blank" rel="noopener noreferrer">
            KB Reasoning in RoboSherlock
        </a>
        <a type="button" class="btn link-button mb-2"
        href="http://www.open-ease.org/perception-for-everyday-manipulation-work/"
        target="_blank" rel="noopener noreferrer">
            Publications
        </a>
    </div>
    <div class="col-12 col-md-7 px-0 mt-3 mt-md-0 mb-3">
        <div class="pl-md-4">
            <div class="video-container">
                <iframe class="responsive-iframe"
                src="https://www.youtube.com/embed/ECw-FSSD9K0?feature=oembed"
                frameborder="0" allowfullscreen></iframe>
            </div>
        </div>
    </div>
</div>
{% endblock %}


{% block details %}
<div class="row">
    <div class="col-lg-8 px-0">
        <p>
            Recognizing class/instance labels and 6DOF position of objects is necessary for a robot perception system, but it is not sufficient for achieving human-like manipulation of objects. Executing a task often means detecting functional parts of objects, deducing what object is missing from a scene, finding objects contained in other objects and so on. These tasks are usually highly knowledge intensive and go beyond the capabilities of the perception systems currently used in robotics. RoboSherlock acts as a middle-ware for perception algorithms, offering solutions for reasoning about perception tasks that the robot can execute and seamless integration for existing robot perception systems. It builds on the concept of <a class="text-link" href="http://uima.apache.org/">unstructured information management (UIM)</a>, which was successfully applied in natural language processing for open-question answering.
        </p>
        <h3>
            Description of the Data
        </h3>
        <p>
            Given an input image or a sequence of images, RoboSherlock first generates object hypotheses. These hypotheses, can be for example supporting planes, point clusters or image regions. Subsequently these hypotheses are further investigated by expert perception algorithms, that return annotations such as shape, colour, location, etc. Using these pieces of information RoboSherlock decides on which object is the one needed for a certain manipulation task, and identifies functional parts of these objects (e.g. handle of a cup, opening of a bottle etc. ).
        </p>
        <div class="pb-3 px-0 px-md-2">
            <a href="{{ url_for('static', filename='img/overview/perception-for-everyday-manipulation/annotated_scene.png')}}">
                <img class="col-12 px-0" 
                src="{{ url_for('static', filename='img/overview/perception-for-everyday-manipulation/annotated_scene_small.png')}}"
                alt="">
            </a>
        </div>
        <p>
            More detail about RoboSherlock itâ€™s data representation results it produces can be found on the <a class="text-link" href="http://www.pr2-looking-at-things.com/">project website</a>.
        </p>
    </div>
    <div class="col-lg-4 px-0 pl-lg-3">
        <div class="row">
            <a class="col-12 col-md-6 col-lg-12 my-3 px-0 px-md-2" href="{{ url_for('static', filename='img/overview/perception-for-everyday-manipulation/pr2-looking_2_small.jpg')}}">
                <img class="col-12 px-0" 
                src="{{ url_for('static', filename='img/overview/perception-for-everyday-manipulation/pr2-looking_2.jpg')}}"
                alt="">
            </a>
            <a class="col-12 col-md-6 col-lg-12 my-3 px-0 px-md-2" href="{{ url_for('static', filename='img/overview/perception-for-everyday-manipulation/scene_annotated.png')}}">
                <img class="col-12 px-0"
                src="{{ url_for('static', filename='img/overview/perception-for-everyday-manipulation/scene_annotated.png')}}"
                alt="">
            </a>
        </div>
    </div>
</div>
{% endblock %}


{% block acknowledgements_class %}
{% endblock %}

{% block acknowledgements %}
<p>
    The development of RoboSherlock has received funding from the EU FP7 RoboHow, ACAT and the SAPHARI project:
</p>
<div class="row pt-md-3 pb-5 justify-content-center">
    <a class="row align-items-center my-2 mx-md-3" href="http://www.robohow.eu/"
    target="_blank" rel="noopener noreferrer">
        <img class="col-12"
        src="{{ url_for('static', filename='img/overview/acknowledgements/robohow.png')}}"
        alt="robohow logo">
    </a>
    <a class="my-2 mx-md-3" href="http://www.acat-project.eu/"
    target="_blank" rel="noopener noreferrer">
        <img id="acat-logo" class="col-12"
        src="{{ url_for('static', filename='img/acat_logo-w-background.png')}}"
        alt="ACAT logo">
    </a>
    <a class="row align-items-center my-2 mx-md-3" href="http://saphari.eu/"
    target="_blank" rel="noopener noreferrer">
        <img id="saphari-logo" class="col-12 px-0"
        src="{{ url_for('static', filename='img/overview/acknowledgements/saphari-cover.png')}}"
        alt="saphari logo">
    </a>
</div>
{% endblock %}
